{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04217a-3e1a-4d7f-842a-2b6b71ade755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline # This tells the IPython environment to draw the plots immediately after the current cell\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 # The deep learning training architecture used\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a23137e-0836-4087-a26f-1420a95f3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure tensorflow's version is 1.13.1\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24661be-fdc9-4de2-a9a9-9eb897dfcca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to download data and extract\n",
    "def get_data_extract():\n",
    "  if \"food-101\" in os.listdir():\n",
    "    print(\"Dataset already exists\")\n",
    "  else:\n",
    "    print(\"Downloading the data...\")\n",
    "    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "    print(\"Dataset downloaded!\")\n",
    "    print(\"Extracting data..\")\n",
    "    !tar xzvf food-101.tar.gz\n",
    "    print(\"Extraction done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1189e1-7eb6-4ba8-bd27-409d93bdda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and extract it to folder\n",
    "get_data_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d686b9-7a2f-4c19-b8b4-9113cbaae435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get food list\n",
    "data_dir = \"food-101/images/\"\n",
    "foods_sorted = sorted(os.listdir(data_dir))\n",
    "print(foods_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad9e83a-2c6a-4369-9164-5cafd04683f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to split dataset into train and test folders\n",
    "def prepare_data(filepath, src,dest):\n",
    "  classes_images = defaultdict(list)\n",
    "  with open(filepath, 'r') as txt:\n",
    "      paths = [read.strip() for read in txt.readlines()]\n",
    "      for p in paths:\n",
    "        food = p.split('/')\n",
    "        classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "  for food in classes_images.keys():\n",
    "    print(\"\\nCopying images into \",food)\n",
    "    if not os.path.exists(os.path.join(dest,food)):\n",
    "      os.makedirs(os.path.join(dest,food))\n",
    "    for i in classes_images[food]:\n",
    "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "  print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cab4f1-892e-43d8-91a1-9dfe35c3cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train dataset by copying images from food-101/images to food-101/train using the file train.txt\n",
    "print(\"Creating train data...\")\n",
    "prepare_data('food-101/meta/train.txt', 'food-101/images', 'train')\n",
    "print()\n",
    "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
    "print(\"Creating test data...\")\n",
    "prepare_data('food-101/meta/test.txt', 'food-101/images', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d268b-0ea6-4298-8dd9-450e5c2d7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to create train_mini and test_mini data samples\n",
    "def dataset_mini(food_list, src, dest):\n",
    "  if os.path.exists(dest):\n",
    "    rmtree(dest) # Removing dataset_mini (if it already exists) folders so that we will have only the classes that we want\n",
    "  os.makedirs(dest)\n",
    "  for food_item in food_list :\n",
    "    print(\"Copying images into\",food_item)\n",
    "    copytree(os.path.join(src,food_item), os.path.join(dest,food_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d5817-1a78-4c24-b43a-54e499adb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking 4 food items and generating separate data folders for the same\n",
    "food_list = ['french_fries','fried_rice','grilled_salmon','steak']\n",
    "src_train = 'train'\n",
    "dest_train = 'train_mini'\n",
    "src_test = 'test'\n",
    "dest_test = 'test_mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b981b3-b6ff-4398-a6a5-0af527d8defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train data folder with new classes\")\n",
    "dataset_mini(food_list, src_train, dest_train)\n",
    "print(\"Done\")\n",
    "print()\n",
    "print(\"Creating test data folder with new classes\")\n",
    "dataset_mini(food_list, src_test, dest_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f70ce3-1384-4eb0-b8d0-99d0fb1e74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in train folder\")\n",
    "!find train_mini -type d -or -type f -printf '.' | wc -c\n",
    "print(\"Total number of samples in test folder\")\n",
    "!find test_mini -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320582b7-6a12-4af5-993b-81db4f500431",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "n_classes = 4\n",
    "img_width, img_height = 299, 299\n",
    "train_data_dir = 'train_mini'\n",
    "validation_data_dir = 'test_mini'\n",
    "nb_train_samples = 3000 #75750\n",
    "nb_validation_samples = 1000 #25250\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Model\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(n_classes,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inception.input, outputs=predictions)\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load the saved weights of the model and continue training\n",
    "model.load_weights('model/best_model_4class.hdf5')\n",
    "\n",
    "# Callbacks\n",
    "checkpointer = ModelCheckpoint(filepath='model/best_model_4class.hdf5', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('model/history_4class.log')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = nb_train_samples // batch_size,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=nb_validation_samples // batch_size,\n",
    "                    epochs=20,\n",
    "                    initial_epoch=18,\n",
    "                    verbose=1,\n",
    "                    callbacks=[csv_logger, checkpointer])\n",
    "\n",
    "model.save('model/model_trained_4class.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303f933-61b7-450e-bf41-d7f0fad5eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map_4 = train_generator.class_indices\n",
    "print(class_map_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2bf10-4466-4f46-915f-25f77f70944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT RESULTS SHOW OVERFITTING. BUT THIS IS BECAUSE I USED 4 LABELS TO TRAIN THE MODEL AND BATCH SIZE OF 64 INSTEAD OF 16 - NOT IMPORTANT AT THE MOMENT.\n",
    "# LATER: NEED TO RE-TRAIN TO *SHOW* BETTER RESULTS\n",
    "\n",
    "# Load the data from the .txt file into a pandas dataframe\n",
    "history_4class = pd.read_csv('model/history_4class.txt')\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.plot(history_4class['epoch'], history_4class['acc'], label='train_accuracy')\n",
    "plt.plot(history_4class['epoch'], history_4class['val_acc'], label='validation_accuracy')\n",
    "plt.title('Accuracy Plot')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the loss\n",
    "plt.plot(history_4class['epoch'], history_4class['loss'], label='train_loss')\n",
    "plt.plot(history_4class['epoch'], history_4class['val_loss'], label='validation_loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcfc1bf-31a6-4695-86ca-3366aa7af821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best saved model to make predictions\n",
    "K.clear_session()\n",
    "model_best = load_model('model/model_trained_4class.hdf5',compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7adfe2f-cd82-420d-a832-3e5d804ffa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the food list manually \n",
    "food_list = ['french_fries','fried_rice','grilled_salmon','steak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22e717-e9c3-4487-af3d-4e0b0bbd9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, images, show = True):\n",
    "  for img in images:\n",
    "    img = image.load_img(img, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)                    \n",
    "    img = np.expand_dims(img, axis=0)         \n",
    "    img /= 255.                                      \n",
    "\n",
    "    pred = model.predict(img)\n",
    "    index = np.argmax(pred)\n",
    "    food_list.sort()\n",
    "    pred_value = food_list[index]\n",
    "    if show:\n",
    "        plt.imshow(img[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.title(pred_value)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb44a8-a81f-4c55-bd63-2462293365ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of downloaded images and test the trained model\n",
    "images = []\n",
    "images.append('test_images/ff.jpg')\n",
    "images.append('test_images/fr.jpg')\n",
    "images.append('test_images/gs.jpg')\n",
    "images.append('test_images/s.jpg')\n",
    "\n",
    "predict_class(model_best, images, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e106d2-5ec1-4aef-9ff0-10d9c7b0f4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
